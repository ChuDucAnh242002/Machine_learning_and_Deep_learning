{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7f47b2",
   "metadata": {},
   "source": [
    "**Important! Please do not remove any cells, including the test cells, even if they appear empty. They contain hidden tests, and deleting them could result in a loss of points, as the exercises are graded automatically. Only edit the cells where you are instructed to write your solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f7199d-c442-4732-ab89-83bda42682a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de21aae042b148f4ce345abc2630f326",
     "grade": false,
     "grade_id": "cell-b2bf973e50b54a30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 5: Machine Translation with Transformers\n",
    "\n",
    "In this exercise, you will explore the Transformer-based neural architecture by tackling a machine translation task. Machine translation involves translating text from a source language to a target language. Traditionally, machine translation was performed using recurrent neural network (RNN)-based architectures. However, the emergence of Transformers has marked a revolutionary shift in the fields of text analysis and especially machine translation.\n",
    "\n",
    "Transformers offer several advantages over earlier RNN-based models for the machine translation task:\n",
    "\n",
    "* One major benefit is their ability to capture context from a long sequence using self-attention layers, which allows the model to retain relevant information from words further back in the text.\n",
    "  \n",
    "* Additionally, Transformers improve the natural flow and grammatical accuracy of translated sentences. Unlike RNN models, which tend to follow the word order of the source language, Transformers utilize cross-attention layers between the source and target languages. This allows them to arrange translated words in an order that sounds more natural in the target language, even if it differs significantly from the source structure.\n",
    "  \n",
    "* Finally, Transformers enable parallelization, which makes it feasible to train them on multiple GPUs, speeding up the training process. \n",
    "\n",
    "\n",
    "To complete this assignment, you will progress through four different stages (tasks):\n",
    "\n",
    "**Task 1. Data Preparation (5 points)**\n",
    "\n",
    "**Task 2. Model Architecture (5 points)**\n",
    "\n",
    "**Task 3. Training and Evaluation (5 points)**\n",
    "\n",
    "**Task 4. Autoregressive Translation (5 points)**\n",
    "\n",
    "### **Deliverables:** \n",
    "\n",
    "Please submit below files to Moodle:\n",
    "\n",
    "* ex5.ipynb\n",
    "* 'model.pth'\n",
    "* 'translation.npy'\n",
    "\n",
    "### **Data**\n",
    "\n",
    "The dataset used for this exercise consists of a set of French sentenceas and their equivalent English translations.\n",
    "\n",
    "*Note:* Your dataset path should point to the \"dataset_ex5\" folder, which contains two CSV files, each containing 137860 short sentences:\n",
    "\n",
    "    small_vocab_fr.csv: French sentences.\n",
    "    small_vocab_en.csv: Corresponding English translations.\n",
    "\n",
    "Be mindful of any extra folder levels that may be created when extracting the \"dataset_ex5.zip\" file.\n",
    "\n",
    "### **Useful links**\n",
    "\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "\n",
    "\n",
    "After downloading the data and setting up the folders, you are ready to begin the exercise tasks. Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f8445f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = False   # You can set it to True if you want to run inference on your trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644c92a-195e-42a9-b63b-0f58e1f13518",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b68dce5af274ba1b727d3e111bc7e14c",
     "grade": true,
     "grade_id": "cell-19ab751311f3561a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4929157-7d8f-4e84-85f6-c56ea7093ae1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "188b80bd0b4c8442090aaa7246bee938",
     "grade": false,
     "grade_id": "cell-172f7e1657a03eb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Add path to the folder containing csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959359d2-e60b-4dec-a5eb-d7dabe3f1a5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"dataset_ex5\" # you can change the path if you want to store the dataset somewhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cfe39-11bc-4c1a-9b6b-1d392a7bbd2c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63ec67478d6d210d0d333ae8d6cd039c",
     "grade": true,
     "grade_id": "cell-ca1abf7548a13d3b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb6f08",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8527fd780788625a34b40348b30de440",
     "grade": false,
     "grade_id": "cell-39478e54ddb16815",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6feccd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seeds for all libraries\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1) \n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607dc4e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "535faf5a7df324791294b2fd542d2d89",
     "grade": false,
     "grade_id": "cell-815c797e06bdf55a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Select the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9f32a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "310824e7fb50a67093ebb7f92521f386",
     "grade": false,
     "grade_id": "cell-3ac688ddcdf1f718",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ed6c0-92b9-4ca5-8b9f-71995799314f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "851f4281950105edf2038c35a19db963",
     "grade": false,
     "grade_id": "cell-91357d14fc99d39d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 1: Data Preparation (5 Points)\n",
    "\n",
    "In this task, you will preprocess the dataset to convert it into a format suitable for input to a Transformer neural model. Each subtask focuses on a specific step in the preprocessing pipeline.\n",
    "\n",
    "### Summary of Tasks for This Stage\n",
    "\n",
    "**Task 1.1: Tokenizaion** (1 point)\n",
    "\n",
    "**Task 1.2: Building Vocabulary** (1 point)\n",
    "\n",
    "**Task 1.3: Sentence Embedding** (1 points)\n",
    "\n",
    "**Task 1.4: Positional Encodding** (2 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9febf38-0a1a-4ff3-94a7-eb232c21eef1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f4723736e3e4512d6d08504b7a0dbd6",
     "grade": false,
     "grade_id": "cell-291860bd3393c1d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.1: Tokenizaion\n",
    "\n",
    "In this task, we use a basic tokenization method for simplicity and to avoid potential library mismatch issues that could arise across different students' systems and environments. While more advanced tokenization methods are available through specialized libraries, this basic approach ensures consistency and focuses on the core concept of tokenization. Our method uses Python's built-in tools and includes the following steps: \n",
    "\n",
    "1. Lowercasing: Convert all characters in the sentence to lowercase.\n",
    "2. Filtering Characters: Define a set of characters to be removed from the sentences, replacing them with an empty string.\n",
    "3. Splitting: Split the sentence into tokens based on spaces.\n",
    "   \n",
    "Run the cell below to load the data, observe basic statistics, and examine some sample sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ecf7ac-b2ce-4e9e-9560-8bc53c616282",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 137860 English sentences in data\n",
      "There are 137860 French sentences in data\n",
      "Here are some examples:\n",
      "----------\n",
      "new jersey is sometimes quiet during autumn \n",
      "new jersey est parfois calme pendant l' automne \n",
      "----------\n",
      "they like strawberries \n",
      "ils aiment les fraises \n",
      "----------\n",
      "she plans to visit the united states next may .\n",
      "elle envisage de se rendre aux états-unis en mai prochain .\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "en_df = pd.read_csv(os.path.join(path , 'small_vocab_en.csv'), header=None, usecols=[0])\n",
    "fr_df = pd.read_csv(os.path.join(path, 'small_vocab_fr.csv'), header=None, usecols=[0])\n",
    "\n",
    "english_sentences = en_df[0].values\n",
    "french_sentences = fr_df[0].values\n",
    "\n",
    "print(f'There are {len(english_sentences)} English sentences in data')\n",
    "print(f'There are {len(french_sentences)} French sentences in data')\n",
    "print('Here are some examples:')\n",
    "e = [ 0, 1000, 3000]\n",
    "for i in e:\n",
    "    print(10*\"-\")\n",
    "    print(english_sentences[i])\n",
    "    print(french_sentences[i])\n",
    "print(100*\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30eefb6-5483-4cf5-839c-eb72aa892eb8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d56cb799102b3f767bfccf73c33b13e3",
     "grade": false,
     "grade_id": "cell-e1accedab7f1151b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Complete the \"tokenize\" function by filling in the blanks based on the detailed guidance provided within the code comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a18098-1a7f-4758-84f4-4a7f6bfa40d3",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e136e2d6e0d0fe41dcc0ed1b4265e4b3",
     "grade": false,
     "grade_id": "cell-d953178b4a066fcc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "['new', 'jersey', 'is', 'sometimes', 'quiet', 'during', 'autumn']\n",
      "['new', 'jersey', 'est', 'parfois', 'calme', 'pendant', \"l'\", 'automne']\n",
      "----------\n",
      "['they', 'like', 'strawberries']\n",
      "['ils', 'aiment', 'les', 'fraises']\n",
      "----------\n",
      "['she', 'plans', 'to', 'visit', 'the', 'united', 'states', 'next', 'may']\n",
      "['elle', 'envisage', 'de', 'se', 'rendre', 'aux', 'étatsunis', 'en', 'mai', 'prochain']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize function \n",
    "def tokenize(sentences):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of sentences by:\n",
    "    1. Converting all text to lowercase.\n",
    "    2. Removing special characters listed in \"filters\".\n",
    "    Hint: you can use \"str.maketrans\" to creates a translation table to remove unwanted characters defined in \"filters\".\n",
    "    3. Splitting each sentence into a list of words.\n",
    "    \"\"\"\n",
    "    filters = '.?!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n'\n",
    "\n",
    "    translation_table = str.maketrans('', '', filters)\n",
    "\n",
    "    tokenized_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.translate(translation_table)\n",
    "        words = sentence.split()\n",
    "        tokenized_list.append(words)\n",
    "    \n",
    "    return tokenized_list\n",
    "    \n",
    "# Tokenize English and French sentences\n",
    "tokenized_en = tokenize(english_sentences)\n",
    "tokenized_fr = tokenize(french_sentences)\n",
    "for i in e:\n",
    "    print(10*\"-\")\n",
    "    print(tokenized_en[i])\n",
    "    print(tokenized_fr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aec479-83e4-447c-8a1d-3fdb7345e560",
   "metadata": {},
   "source": [
    "Run the cell below to check the correctness of your solution to the tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa45a918-bf00-4e55-b019-931c192d0d31",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "669ef31e0c8851864a0dd34bbc381a22",
     "grade": true,
     "grade_id": "cell-ddea51129d5d8a84",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: The tokenize function is working as expected.\n"
     ]
    }
   ],
   "source": [
    "# Visible tests here\n",
    "\n",
    "# Test the tokenize function with example sentences\n",
    "test_sentences = [\"Hello, world!\", \"Python is fun.\", \"Let's tokenize this: right?\"]\n",
    "\n",
    "# Expected output: lowercase, special characters removed, tokenized words\n",
    "expected_output = [\n",
    "    [\"hello\", \"world\"],\n",
    "    [\"python\", \"is\", \"fun\"],\n",
    "    [\"let's\", \"tokenize\", \"this\", \"right\"]\n",
    "]\n",
    "\n",
    "# Run the student's tokenize function\n",
    "tokenized_output = tokenize(test_sentences)\n",
    "\n",
    "# Check if the output matches the expected output\n",
    "assert tokenized_output == expected_output, (\n",
    "    f\"Test failed!\\nExpected: {expected_output}\\nGot: {tokenized_output}\")\n",
    "print(\"Test passed: The tokenize function is working as expected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc71a52-0148-4bce-af72-799047b0f653",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0907496be0bbf0e8a9587a38d054ac63",
     "grade": false,
     "grade_id": "cell-5c42169eb0d9ba7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.2: Building Vocabulary\n",
    "\n",
    "In this step, we will convert tokenized sentences into lists of integers. This is achieved by defining a dictionary of unique words for each language and assigning a unique integer to each word.\n",
    "\n",
    "You may recall practicing a similar concept in Exercise 4, where you built a character-based dictionary. In this exercise, we are building a word-level dictionary, where each entry in the dictionary represents a unique word.\n",
    "\n",
    "In addition to the set of unique words in the dataset, the vocabulary must include three special tokens:\n",
    "\n",
    "1.  PAD: Padding Token (0)\n",
    "2.  SOS: Start of Sentence (1)\n",
    "3.  EOS: End of Sentence (2)\n",
    "\n",
    "Complete the \"build_vocab\" function by filling in the blanks according to the provided instructions in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1d488c-b866-46da-91c9-857bc7540d7b",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54b4b871a691fb80fb59f818abe16af6",
     "grade": false,
     "grade_id": "cell-acd8f7a88e74d5a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples from our English dictionary: \n",
      "----------------------------------------------------------------------------------------------------\n",
      "word: <PAD>, index: 0\n",
      "word: <SOS>, index: 1\n",
      "word: <EOS>, index: 2\n",
      "word: is, index: 3\n",
      "word: during, index: 4\n",
      "word: the, index: 5\n",
      "word: fruit, index: 6\n",
      "word: never, index: 7\n",
      "word: sometimes, index: 8\n",
      "word: usually, index: 9\n",
      "__________\n",
      "index: 0, word: <PAD>\n",
      "index: 1, word: <SOS>\n",
      "index: 2, word: <EOS>\n",
      "index: 3, word: is\n",
      "index: 4, word: during\n",
      "index: 5, word: the\n",
      "index: 6, word: fruit\n",
      "index: 7, word: never\n",
      "index: 8, word: sometimes\n",
      "index: 9, word: usually\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary with special tokens\n",
    "def build_vocab(tokenized_sentences):\n",
    "    special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "    # build vocab by applying \"Counter\" for sentence in tokenized_sentences and for token in sentence\n",
    "    # add special tokens\n",
    "    # word2idx = ? (a dictionary for mapping word to index)\n",
    "    # idx2word = ? (a dictionary for index to word)\n",
    "\n",
    "    all_tokens = [token for sentence in tokenized_sentences for token in sentence]\n",
    "\n",
    "    token_counts = Counter(all_tokens)\n",
    "\n",
    "    unique_tokens = sorted(token_counts.keys(), key=lambda x: (-token_counts[x], x))\n",
    "    vocab = special_tokens + unique_tokens\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    \n",
    "    return word2idx, idx2word\n",
    "\n",
    "en_word2idx, en_idx2word = build_vocab(tokenized_en)\n",
    "fr_word2idx, fr_idx2word = build_vocab(tokenized_fr)\n",
    "\n",
    "print(\"Here are some examples from our English dictionary: \")\n",
    "print(100 * \"-\")\n",
    "\n",
    "# Display first 10 words and their indices from en_word2idx\n",
    "for i, (key, value) in enumerate(en_word2idx.items()):\n",
    "    print(f'word: {key}, index: {value}')\n",
    "    if i == 9:  # After 10 iterations, break\n",
    "        break\n",
    "\n",
    "print(10 * \"_\")\n",
    "\n",
    "# Display first 10 indices and their words from en_idx2word\n",
    "for i, (key, value) in enumerate(en_idx2word.items()):\n",
    "    print(f'index: {key}, word: {value}')\n",
    "    if i == 9:  # After 10 iterations, break\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fc4ac-53c1-4bf7-bd42-a7d601723865",
   "metadata": {},
   "source": [
    "Run the cell below to check the correctness of your solution to the build_vocab function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f547dd82-5bb6-47fb-b0dc-b0800fb904b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb9622630aba9ccc7f1c35973ebe1fb1",
     "grade": true,
     "grade_id": "cell-ba37faad4f92cb66",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary test passed!\n"
     ]
    }
   ],
   "source": [
    "# Visible tests here\n",
    "\n",
    "# Test: Check if the vocabulary is built correctly\n",
    "\n",
    "# Tokenized test data\n",
    "sample_tokenized_sentences = [[\"hello\", \"world\"], [\"hello\", \"my\", \"friend\"]]\n",
    "\n",
    "# Expected results\n",
    "expected_special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "expected_vocab = expected_special_tokens + [\"friend\", \"hello\", \"my\", \"world\"]\n",
    "\n",
    "# Build vocabulary\n",
    "word2idx, idx2word = build_vocab(sample_tokenized_sentences)\n",
    "\n",
    "# Test special tokens are present and in correct order\n",
    "assert all(token in word2idx for token in expected_special_tokens), \"Special tokens missing from vocabulary\"\n",
    "assert word2idx[\"<PAD>\"] == 0, \"<PAD> token index is incorrect\"\n",
    "assert word2idx[\"<SOS>\"] == 1, \"<SOS> token index is incorrect\"\n",
    "assert word2idx[\"<EOS>\"] == 2, \"<EOS> token index is incorrect\"\n",
    "\n",
    "# Test all unique words are present and sorted correctly\n",
    "assert sorted(word2idx.keys()) == sorted(expected_vocab), \"Vocabulary does not match expected words\"\n",
    "assert len(word2idx) == len(idx2word), \"Mismatch between word2idx and idx2word lengths\"\n",
    "assert all(idx2word[word2idx[word]] == word for word in word2idx), \"word2idx and idx2word mappings are incorrect\"\n",
    "\n",
    "print(\"Vocabulary test passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604ca38-063e-46cb-a40e-57192653a316",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc164a3386abefc31af298f532ab98d0",
     "grade": false,
     "grade_id": "cell-2b2c9232a9907c80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Dataset Class\n",
    "\n",
    "In this step, we will use a custom dataset class specifically designed for our translation task. You do not need to implement anything for this step, as the dataset class is already provided for you. This class incorporates essential preprocessing steps, such as padding, truncation, and the addition of special tokens.\n",
    "\n",
    "As discussed earlier, sentences in our dataset have varying lengths. To ensure all sentences are of the same length (a requirement for the Transformer model), we will define a fixed length for input sequences. The preprocessing steps performed by the dataset class include:\n",
    "\n",
    "* Special Tokens: The 'SOS' token is added at the beginning of each sentence, and the 'EOS' token is added at the end.\n",
    "* Truncation: Sentences that exceed the defined maximum length will be truncated to fit the specified length.\n",
    "* Padding: The 'PAD' token is appended to sentences shorter than the maximum length until they reach the required length.\n",
    "\n",
    "Take some time to go through the dataset class and its methods to observe how these preprocessing steps are implemented. Understanding the class structure will help you in tasks where you might need to customize or extend the dataset functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742ff0d6-758b-43c6-a870-aab4a73746dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source batch: tensor([[ 1,  5, 25,  3, 11, 59,  4, 46,  2,  0]])\n",
      "torch.Size([1, 10])\n",
      "__________\n",
      "Target batch: tensor([[ 1, 20,  3,  8, 65,  4, 39,  2,  0,  0]])\n",
      "torch.Size([1, 10])\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "# Dataset class with padding applied in __getitem__\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab, seq_len=30):\n",
    "        self.src_sentences = src_sentences\n",
    "        self.tgt_sentences = tgt_sentences\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def pad_sequence(self, tokens, vocab, is_target=False):\n",
    "        \"\"\"\n",
    "        Pads a sequence of tokens to the fixed length `seq_len`.\n",
    "        Adds <SOS> at the start, <EOS> at the end, and pads with <PAD>.\n",
    "        Trims if the sequence is longer than `seq_len`.\n",
    "        \"\"\"\n",
    "        tokens = [vocab[\"<SOS>\"]] + [vocab.get(token, vocab[\"<PAD>\"]) for token in tokens]\n",
    "        tokens.append(vocab[\"<EOS>\"])  \n",
    "        tokens = tokens[:self.seq_len]  \n",
    "        tokens += [vocab[\"<PAD>\"]] * (self.seq_len - len(tokens))  \n",
    "        return tokens\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        src_tokens = self.src_sentences[idx]\n",
    "        tgt_tokens = self.tgt_sentences[idx]\n",
    "        \n",
    "        # Apply padding to both the source and target sentences\n",
    "        src_padded = self.pad_sequence(src_tokens, self.src_vocab, is_target=False)\n",
    "        tgt_padded = self.pad_sequence(tgt_tokens, self.tgt_vocab, is_target=True)\n",
    "        \n",
    "        # Convert to tensors and move to device (GPU or CPU)\n",
    "        src_item = torch.tensor(src_padded).to(device)\n",
    "        tgt_item = torch.tensor(tgt_padded).to(device)\n",
    "    \n",
    "        return src_item, tgt_item\n",
    "\n",
    "# Instantiate and test the dataset, let the French be as source language and English as target language.\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Test the DataLoader\n",
    "for src_batch, tgt_batch in dataloader:\n",
    "    print(\"Source batch:\", src_batch)\n",
    "    print(src_batch.size())\n",
    "    print(10*\"_\")\n",
    "    print(\"Target batch:\", tgt_batch)\n",
    "    print(tgt_batch.size())\n",
    "    print(10*\"_\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cbf6fe-050c-4357-ae8f-112a4021b231",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a920ba916dac6fa8032a24c0603867eb",
     "grade": false,
     "grade_id": "cell-5ddb30e4fc5234fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.3: Sentence Embedding\n",
    "\n",
    "Words, by themselves, are discrete symbols that neural networks cannot process directly. To make them understandable to the model, we use **embedding layers**. These layers transform words or tokens into dense, fixed-size vectors, where each word is represented by a unique vector. The embedding layer maps words into a continuous vector space, enabling semantically similar words to be closer to each other in this space. This approach is far more compact and efficient than sparse, high-dimensional representations like one-hot encoding.\n",
    "\n",
    "Embedding layers are particularly useful in natural language processing tasks such as **machine translation**, where words in different languages must be represented in a way that enables the model to learn their relationships.\n",
    "\n",
    "In this step, you are asked to define separate PyTorch embedding layers for both the source and target languages, and then pass the src_batch and tgt_batch through these layers. In the cell below, complete the code by filling in the blanks according to the provided instructions. After running the cell, pay attention to the input and output dimensions of the embedding layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe7f794-94bc-4332-a186-7c0d11fc218f",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e641ffdf106f543f00d6a776e3963eb",
     "grade": false,
     "grade_id": "cell-fab72a3e23c8b68e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 128])\n",
      "__________\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "vsize_src = len(fr_word2idx)\n",
    "vsize_tgt = len(en_word2idx)\n",
    "\n",
    "# data: let the French be as source language and English as target language.\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Use 'next' to get a batch from the DataLoader iterator\n",
    "src_batch, tgt_batch = next(iter(dataloader))\n",
    "\n",
    "embedding_fr = nn.Embedding(num_embeddings=vsize_src, embedding_dim=embedding_size)\n",
    "embedding_fr.to(device)\n",
    "output_embedding_fr = embedding_fr(src_batch.to(device))\n",
    "\n",
    "embedding_en = nn.Embedding(num_embeddings=vsize_tgt, embedding_dim=embedding_size)\n",
    "embedding_en.to(device)\n",
    "output_embedding_en = embedding_en(tgt_batch.to(device))\n",
    "\n",
    "print(10*\"_\")\n",
    "print(src_batch.size())\n",
    "print(output_embedding_fr.size())\n",
    "print(10*\"_\")\n",
    "print(tgt_batch.size())\n",
    "print(output_embedding_en.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc911b0-97c1-4924-817f-417696c65d44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5ad5665bb0536a3e107f8d3e8668419",
     "grade": false,
     "grade_id": "cell-db2fee17b9a7a42a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Run the cell below to check the correctness of your solution for the sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30669a20-b2f9-4e86-96ac-15af4cdb01b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b92c388bc76a10fd0d9eb5193c0008",
     "grade": true,
     "grade_id": "cell-3e23c383eb021716",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings are correctly implemented!\n"
     ]
    }
   ],
   "source": [
    "# Visible tests here\n",
    "\n",
    "# Check if the embeddings have the correct output shapes\n",
    "assert output_embedding_fr.shape == (src_batch.size(0), src_batch.size(1), embedding_size), \"Embedding for French is incorrect!\"\n",
    "assert output_embedding_en.shape == (tgt_batch.size(0), tgt_batch.size(1), embedding_size), \"Embedding for English is incorrect!\"\n",
    "\n",
    "print(\"Embeddings are correctly implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8ae0f-ece1-4596-8037-89631b8d2075",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "478bcf1a7168a93463c0482b18b80bbf",
     "grade": false,
     "grade_id": "cell-8372a80b53e83a10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 1.4: Positional encoding\n",
    "\n",
    "In sequence models like the Transformer, the model needs a way to understand the relative positions of words in a sequence. Since the Transformer model does not inherently process sequential data in a time-dependent manner (unlike RNNs or LSTMs), we need to explicitly provide information about the position of each word in the input sequence.\n",
    "\n",
    "The Positional Encoding layer is used to add this positional information to the word embeddings. It generates a vector for each position in the sequence and combines it with the word embedding to provide both the content and position information. The positional encoding is computed using sine and cosine functions of different wavelengths, which allows the model to easily learn relative positions.\n",
    "\n",
    "In this step, your task is to implement the Positional Encoding layer. You should:\n",
    "\n",
    "1. Compute the positional encodings using sine and cosine functions.\n",
    "2. Register the positional encodings as a buffer so they are not considered trainable parameters.\n",
    "3. Add the positional encoding to the word embeddings during the forward pass.\n",
    "\n",
    "Once you have implemented the layer, you can test if it works correctly by running the test cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dfbfdac1-3bd3-4a57-b034-4aeb97cf1b9d",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66ff2d4d083b95d6edb7f6e17233b63e",
     "grade": false,
     "grade_id": "cell-de1d08bfdff6d81e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_size, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "        # Initialize a tensor to store positional encodings for each position up to max_len\n",
    "        pos_encoding = torch.zeros(max_len, embed_size)\n",
    "        # Create a tensor for positions, where each position corresponds to a word's position in the sequence\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # 1. Create a tensor `div_term` to scale the positional encoding values. \n",
    "        \n",
    "        # Hint:\n",
    "        # This is based on the formula for positional encoding where each dimension has a different frequency.\n",
    "        # We generate a range of values from 0 to embed_size, stepping by 2 (for even indices), and multiply it by a scaling factor.\n",
    "        # The scaling factor (-math.log(10000.0) / embed_size) ensures the frequencies decay logarithmically.\n",
    "        \n",
    "        # 2. Apply the sine function to the even indices of the positional encoding matrix.\n",
    "        # 3. Apply the cosine function to the odd indices of the positional encoding matrix.\n",
    "        \n",
    "        # Hint:\n",
    "        # The `position` tensor holds the position values for each token, and `div_term` scales those values.\n",
    "        \n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, embed_size, 2).float() * (-math.log(10000.0) / embed_size)\n",
    "        )\n",
    "        # self.pos_encoding = pos_encoding\n",
    "        pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # self.posi_encoding = nn.Parameter(pos_encoding.unsqueeze(0), requires_grad=True)\n",
    "        # Register as buffer so it is not considered as a parameter during training\n",
    "        self.register_buffer('pos_encoding', pos_encoding.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding to embeddings\n",
    "        x = x * math.sqrt(self.embed_size)\n",
    "        seq_len = x.size(1)\n",
    "        pos_enc = self.pos_encoding[:, :seq_len, :].to(x.device)\n",
    "        x = x + pos_enc\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f3a3335e-1dff-4fe8-aebd-8367d2359da5",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (512) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#%% Applying positional encoding \u001b[39;00m\n\u001b[0;32m      2\u001b[0m positional_encoding \u001b[38;5;241m=\u001b[39m PositionalEncoding(embedding_size, \u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m output_pe_fr \u001b[38;5;241m=\u001b[39m \u001b[43mpositional_encoding\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_embedding_fr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m output_pe_en \u001b[38;5;241m=\u001b[39m positional_encoding (output_embedding_en)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[140], line 40\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     39\u001b[0m pos_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding[:, :seq_len, :]\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpos_enc\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (512) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "#%% Applying positional encoding \n",
    "positional_encoding = PositionalEncoding(embedding_size, 512)\n",
    "output_pe_fr = positional_encoding (output_embedding_fr)\n",
    "output_pe_en = positional_encoding (output_embedding_en)\n",
    "print(10*\"_\")\n",
    "print(output_pe_fr.size())\n",
    "print(output_pe_en.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6fa00a4a-cbc5-4ef4-873f-b4d0dafa33ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40f67672dff380019505babbe8448301",
     "grade": true,
     "grade_id": "cell-24f5a81611dd6e96",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Encoding has been implemented correctly!\n"
     ]
    }
   ],
   "source": [
    "# Visible tests here\n",
    "\n",
    "# Test if positional encoding has been implemented correctly\n",
    "\n",
    "# Initialize the positional encoding with a fixed embed size and max_len\n",
    "test_pos_enc = PositionalEncoding(embed_size=128, max_len=512)\n",
    "\n",
    "# Let's assume the input sequence is a batch of embeddings (value doesn't matter for this test)\n",
    "src_batch = torch.zeros(1, 10, 128)  # batch_size=1, seq_len=10, embed_size=128\n",
    "tgt_batch = torch.zeros(1, 10, 128)\n",
    "\n",
    "# Pass through the positional encoding layer\n",
    "encoded_src_batch = test_pos_enc(src_batch)\n",
    "encoded_tgt_batch = test_pos_enc(tgt_batch)\n",
    "\n",
    "# Check the output dimensions\n",
    "assert encoded_src_batch.size() == src_batch.size(), f\"Expected {src_batch.size()}, but got {encoded_src_batch.size()}\"\n",
    "assert encoded_tgt_batch.size() == tgt_batch.size(), f\"Expected {tgt_batch.size()}, but got {encoded_tgt_batch.size()}\"\n",
    "\n",
    "# Check if positional encoding is working correctly\n",
    "\n",
    "# Ensure that adding positional encoding to embeddings changes the values\n",
    "# The output at the first position should be different than at other positions (if positional encoding is applied correctly)\n",
    "assert not torch.allclose(encoded_src_batch[:, 0, :], encoded_src_batch[:, 1, :], atol=1e-5), \\\n",
    "    \"Positional encoding should differentiate between different positions in the sequence.\"\n",
    "\n",
    "print(\"Positional Encoding has been implemented correctly!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf7c61-c078-45c3-977e-fbefe51e3beb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29456a0467e8a115f33b88974dd4d293",
     "grade": false,
     "grade_id": "cell-093e16e5c4566696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 2: Model Architecture (5 points)\n",
    "\n",
    "### Summary of Tasks for This Stage\n",
    "\n",
    "**Task 2.1: Designing a basic transformer block** (3 points)\n",
    "\n",
    "**Task 2.2: Adding Encoder and Decoder blocks** (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ff3a1-5f60-4baa-9eb9-17d899db9df5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b95686179c6ec14218111c952981a8a7",
     "grade": false,
     "grade_id": "cell-791a329ab0d9161b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 2.1: Designing a basic transformer block\n",
    "\n",
    "In this task, you will implement a simple Transformer model. This model will take source and target sequences as input, apply embeddings and positional encodings, pass the result through a Transformer block, and finally project the output to the target vocabulary space. Before passing the input through the Transformer block, you need to compute two types of masks:\n",
    "\n",
    "**Padding Mask:** This mask is applied to the source sequence and to the target sequence to prevent the model from attending to padding tokens, which should be ignored during training. The padding mask is implemented in the create_pad_mask method.\n",
    "\n",
    "**Target Mask (tgt_mask):** This mask is used to prevent the model from using future target steps to predict the current output. If the model could access future information, it would already know the solution, making training redundant. The tgt_mask helps ensure causal attention by masking out future tokens in the target sequence.\n",
    "\n",
    "These two masks are essential for enabling effective training and maintaining the correct flow of information through the model. \n",
    "\n",
    "For this task, you can use the pre-implemented embedding and positional encoding blocks. In the MySimpleTransformer template provided below, fill in the blanks as instructed in the code. Once you have implemented the MySimpleTransformer class, you can test the correctness of your solution by running the test cell. \n",
    "\n",
    "You may receive a warning about using 'batch_first' during the initialization of the Transformer block. Please ignore it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4ccdb-b179-4d23-952d-bdc91600d5b6",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45f611a83bbd8d76f72b7ed2a1faff72",
     "grade": false,
     "grade_id": "cell-2c2066cf6ea79138",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MySimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size_src, vocab_size_tgt, embed_size, num_heads, hidden_dim, num_encoder_layers, num_decoder_layers, max_len=512):\n",
    "        super(MySimpleTransformer, self).__init__()\n",
    "        # Initialize layers as below:\n",
    "        # Embedding layer for source language tokens\n",
    "        # embedding layer for target langauge tokens\n",
    "        # Positional encoding\n",
    "        # Transformer block (Hint: use nn.Transformer)\n",
    "        # Final linear layer to project transformer output to vocab size (Hint: use nn.Linear)\n",
    "        \n",
    "        self.embedding_src = nn.Embedding(vocab_size_src, embed_size)\n",
    "        self.embedding_tgt = nn.Embedding(vocab_size_tgt, embed_size)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embed_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size_tgt)\n",
    "        \n",
    "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, tgt_mask=None):\n",
    "        \n",
    "        # 1. Get embeddings for source and target.\n",
    "        # 2. apply positional encoding to embedded source and target\n",
    "        # 3. Forward pass to Transformer block with masking\n",
    "        # 4. Project to vocabulary size\n",
    "        \n",
    "        \n",
    "\n",
    "        src = src.transpose(0, 1)\n",
    "        tgt = tgt.transpose(0, 1)\n",
    "        if tgt_mask != None:\n",
    "            tgt_mask = tgt_mask.transpose(0,1)\n",
    "            \n",
    "        src_embedded = self.embedding_src(src)\n",
    "        tgt_embedded = self.embedding_tgt(tgt)\n",
    "\n",
    "        src_embedded = self.positional_encoding(src_embedded)\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded)\n",
    "\n",
    "        transformer_output = self.transformer(\n",
    "            src=src_embedded,\n",
    "            tgt=tgt_embedded,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "\n",
    "        output = self.fc_out(transformer_output)\n",
    "        \n",
    "        output = output.transpose(0, 1)\n",
    "        return output\n",
    "    \n",
    "    def get_tgt_mask(self, tgt):\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
    "        return tgt_mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix):\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        pad_token = 0\n",
    "        return (matrix == pad_token).float()\n",
    "\n",
    "def get_num_trainable_parameters(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model has {num_params} trainable parameters.')\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "66a7ffba-b4f2-4235-a602-bb6e6394d3ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3ae137376d5258f43b18291c31e94ed",
     "grade": true,
     "grade_id": "cell-feac3c86c1e08168",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10641353 trainable parameters.\n",
      "\u001b[92mGood job! All visible tests passed! You can proceed further.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Visible tests here\n",
    "all_tests_successful = True\n",
    "\n",
    "embedding_size = 512\n",
    "vsize_src = len(fr_word2idx) # 336 \n",
    "vsize_tgt = len(en_word2idx) # 201\n",
    "hdim = 128\n",
    "model = MySimpleTransformer(vsize_src, vsize_tgt, embedding_size, 2, hdim, 3, 3, max_len=512)\n",
    "model = model.to(device)\n",
    "\n",
    "# Data\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "src_batch, tgt_batch = next(iter(dataloader))\n",
    "    \n",
    "tgt_mask = model.get_tgt_mask(tgt_batch)\n",
    "src_padding_mask = model.create_pad_mask(src_batch)\n",
    "tgt_padding_mask = model.create_pad_mask(tgt_batch)\n",
    "output = model(src_batch, tgt_batch, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask )\n",
    "\n",
    "# Check if the output shape is correct: [batch_size, seq_len, vocab_size_tgt]\n",
    "if output.size() != (1, 10, vsize_tgt):\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected output shape (2, 10, {vsize_tgt}), but got {output.size()}\")\n",
    "\n",
    "num_params = get_num_trainable_parameters(model)\n",
    "expected_num_parameters = 10641353\n",
    "if num_params != expected_num_parameters:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected number of trainable parameters {expected_num_parameters}, but got {num_params}.\")\n",
    "\n",
    "\n",
    "if all_tests_successful: \n",
    "    success_str = \"Good job! All visible tests passed! You can proceed further.\"\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fa97de74-2b5a-4521-9474-04f9b7112e0b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "[[ 1 24 23  3 11 31  4 36  2  0]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "torch.Size([10, 10])\n",
      "[[  0. -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0. -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0. -inf -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0. -inf -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0. -inf -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0. -inf -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0. -inf -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0. -inf -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. -inf]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(src_batch.size())\n",
    "print(tgt_batch.size())\n",
    "\n",
    "print(src_padding_mask.size())\n",
    "print(src_batch.cpu().detach().numpy())\n",
    "print(src_padding_mask.cpu().detach().numpy())\n",
    "\n",
    "print(tgt_mask.size())\n",
    "print(tgt_mask.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03f944-f320-4ab2-ba28-cbeb8cb7927a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ffa9c18d5dc8110338e939c9d337b22",
     "grade": false,
     "grade_id": "cell-c94bd78980ab8c0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Task 2.2: Adding Encoder and Decoder blocks\n",
    "\n",
    "The MySimpleTransformer class you implemented uses the Transformer module of PyTorch, which consists of two main parts: the encoder and the decoder. Each part of the model contains several layers of self-attention and feedforward neural networks, with the encoder and decoder connected by a cross-attention mechanism.\n",
    "\n",
    "**Self-Attention:** In the context of machine translation, self-attention allows each word in a sequence (either in the source or target language) to attend to every other word in the same sequence, regardless of their position. This mechanism enables the model to capture long-range dependencies and relationships within the sentence.\n",
    "\n",
    "**Cross-Attention:** This occurs in the decoder block, where the model attends to the encoder's output. In machine translation, cross-attention allows the decoder to focus on relevant parts of the input sequence (source language) when generating the output sequence (target language). It essentially \"crosses\" between the encoder and decoder, enabling the model to translate based on the context of both source and target sentences.\n",
    "\n",
    "Next, we will modify our Transformer block by manually separating the encoder and decoder components. This separation is necessary because, during inference (translation), the source sentence must pass through the encoder, and the generated target sentence must pass through the decoder one token at a time. This step is crucial since the translation process is autoregressive, meaning each word is predicted based on the previously generated words.\n",
    "\n",
    "In the cell below, complete the MyTransformer class as an updated version of our model class. This updated version will be used to train our neural machine translation system. Ensure that the encoder and decoder components are implemented separately, as this is important for managing the inference process later.\n",
    "\n",
    "Hints:\n",
    "\n",
    "1. The updated model is similar to the simple model from Task 2.1, except that the encoder and decoder are separated to allow individual calls. Remember to include the source and target padding masks, as well as the target causal mask (tgt_mask).\n",
    "\n",
    "2. The layer initialization for the updated model should be identical to the simple model. Specifically, the *init* method of the MyTransformer class should mirror the MySimpleTransformer class.\n",
    "\n",
    "3. Use nn.Transformer.encoder(src_embedded, src_key_padding_mask=src_padding_mask)\n",
    "\n",
    "4. Use nn.Transformer.decoder(tgt_embedded, memory, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
    "\n",
    "Once you have implemented the MyTransformer class, you can test the correctness of your solution by running the test cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a05c4ec1-3f32-4d12-b0e2-a2bd1643b0de",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31b428830c77336df8f215865a3b76a1",
     "grade": false,
     "grade_id": "cell-8acf47d49c2ce752",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size_src, vocab_size_tgt, embed_size, num_heads, hidden_dim, num_encoder_layers, num_decoder_layers, max_len=512):\n",
    "        super(MyTransformer, self).__init__()\n",
    "        # Initialize layers similar to MySimpleTransformer\n",
    "        # Two Embedding layers for source and target text\n",
    "        # Positional encoding\n",
    "        # Transformer block\n",
    "        # Final linear layer to project transformer output to vocab size\n",
    "\n",
    "        self.embedding_src = nn.Embedding(vocab_size_src, embed_size)\n",
    "        self.embedding_tgt = nn.Embedding(vocab_size_tgt, embed_size)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=hidden_dim),\n",
    "            num_layers=num_decoder_layers\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(embed_size, vocab_size_tgt)\n",
    "        \n",
    "    def encode(self, src, src_padding_mask):\n",
    "        # Transpose inputs to (seq_len, batch_size, embedding_dim)\n",
    "        src = src.transpose(0, 1)\n",
    "        \n",
    "        # 1. Get embeddings for source \n",
    "        # 2. apply positional encoding to embedded source \n",
    "        # 3. Forward pass to Transformer encoder block with src_key_padding_mask\n",
    "        \n",
    "        src_embedded = self.embedding_src(src)\n",
    "        src_embedded = self.positional_encoding(src_embedded)\n",
    "        encoded = self.encoder(src_embedded, src_key_padding_mask=src_padding_mask)\n",
    "\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, tgt_padding_mask):\n",
    "        # Transpose inputs to (seq_len, batch_size, embedding_dim)\n",
    "        tgt = tgt.transpose(0, 1)\n",
    "        if tgt_mask != None:\n",
    "            tgt_mask = tgt_mask.transpose(0,1)\n",
    "        # 1. Get embeddings for target\n",
    "        # 2. apply positional encoding to embedded target\n",
    "        # 3. Forward pass target and memory (output of encode) to Transformer decoder block with tgt_mask\n",
    "        \n",
    "        tgt_embedded = self.embedding_tgt(tgt)\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded)\n",
    "        decoded = self.decoder(\n",
    "            tgt_embedded,\n",
    "            memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask\n",
    "        )\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, tgt_mask=None):\n",
    "        # 1. pass source through encode block (name it as memory)\n",
    "        # 2. pass target and memory through decode block\n",
    "        # 3. Project to vocabulary size  \n",
    "        \n",
    "        memory = self.encode(src, src_padding_mask)\n",
    "\n",
    "        output_decoder = self.decode(tgt, memory, tgt_mask, tgt_padding_mask)\n",
    "\n",
    "        output = self.fc_out(output_decoder)\n",
    "        \n",
    "        output = output.transpose(0, 1)\n",
    "        return  output_decoder, output \n",
    "    \n",
    "    def get_tgt_mask(self, tgt):\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
    "        return tgt_mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix):\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        pad_token = 0\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7d421762-6a59-4a20-8c05-594ea71eafac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04f7388c5f52aecc1f8f95d8e53ea635",
     "grade": true,
     "grade_id": "cell-71426ea9698049d6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10639305 trainable parameters.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected number of trainable parameters 10641353, but got 10639305.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_params \u001b[38;5;241m!=\u001b[39m expected_num_parameters:\n\u001b[0;32m     29\u001b[0m     all_tests_successful \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected number of trainable parameters \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_num_parameters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_tests_successful: \n\u001b[0;32m     33\u001b[0m     success_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGood job! All visible tests passed! You can proceed further.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Expected number of trainable parameters 10641353, but got 10639305."
     ]
    }
   ],
   "source": [
    "# Visible tests here\n",
    "all_tests_successful = True\n",
    "\n",
    "embedding_size = 512\n",
    "vsize_src = len(fr_word2idx) # 336 \n",
    "vsize_tgt = len(en_word2idx) # 201\n",
    "hdim = 128\n",
    "model = MyTransformer(vsize_src, vsize_tgt, embedding_size, 2, hdim, 3, 3, max_len=512)\n",
    "model = model.to(device)\n",
    "\n",
    "# Data\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "src_batch, tgt_batch = next(iter(dataloader))\n",
    "    \n",
    "tgt_mask = model.get_tgt_mask(tgt_batch)\n",
    "src_padding_mask = model.create_pad_mask(src_batch)\n",
    "tgt_padding_mask = model.create_pad_mask(tgt_batch)\n",
    "_, output = model(src_batch, tgt_batch, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask )\n",
    "\n",
    "# Check if the output shape is correct: [batch_size, seq_len, vocab_size_tgt]\n",
    "if output.size() != (1, 10, vsize_tgt):\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected output shape (2, 10, {vsize_tgt}), but got {output.size()}\")\n",
    "\n",
    "num_params = get_num_trainable_parameters(model)\n",
    "expected_num_parameters = 10641353\n",
    "if num_params != expected_num_parameters:\n",
    "    all_tests_successful = False\n",
    "    raise AssertionError(f\"Expected number of trainable parameters {expected_num_parameters}, but got {num_params}.\")\n",
    "\n",
    "if all_tests_successful: \n",
    "    success_str = \"Good job! All visible tests passed! You can proceed further.\"\n",
    "    print(f\"\\033[92m{success_str}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478708b-68d0-4690-8bed-3629ea2e4b2d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfdc594c1314d46e6f092e7117d03e55",
     "grade": false,
     "grade_id": "cell-2f77cd749e40453a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 3: Training and Evaluation (5 points)\n",
    "\n",
    "So far, we have defined our dataset class and the Transformer model. The next step is to train and validate the model. We will split the data into training and validation sets, with an 80% training and 20% validation ratio, and run the training and validation loops accordingly.\n",
    "\n",
    "For the model, we will define a simple Transformer with a hidden dimension of 512, 4 encoder layers, 4 decoder layers, and 6 attention heads. We will use cross-entropy loss, which is well-suited for Transformer-based machine translation because it measures the difference between the predicted probability distribution and the true distribution for each token in the sequence. This loss function helps the model optimize the prediction accuracy for each word in the target sequence. Additionally, we will use the Adam optimizer to efficiently minimize the loss. \n",
    "\n",
    "First, run the two cells below to define the data and model with the specified hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5b833b15-348a-447c-9c6e-185ec36736d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e3d07d2cc6c623d73b169e5acc2771b",
     "grade": false,
     "grade_id": "cell-50417a72b48171e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "bs = 256\n",
    "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=7)\n",
    "number_of_sentences = len(tokenized_fr)\n",
    "train_size = int((0.8)*number_of_sentences)\n",
    "test_size = int(number_of_sentences - train_size)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "efd32c9e-9868-4f8a-819d-6816332a9ea7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ada45fd309f153dcb7c3f001c5acddc8",
     "grade": false,
     "grade_id": "cell-47986e3c9b4441ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "embedding_size = 240 # embed_dim must be divisible by num_heads\n",
    "vsize_src = len(fr_word2idx) # 336 \n",
    "vsize_tgt = len(en_word2idx) # 201\n",
    "hdim = 512\n",
    "model = MyTransformer(vsize_src, vsize_tgt, embedding_size, 6, hdim, 4, 4, max_len=256)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a4a14-51e3-42d2-babd-2fd67708cac0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e8a960216e1f9167a4a54e07c15b093",
     "grade": false,
     "grade_id": "cell-e4d856271fb971bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In the cell below, complete the training and validation loops by filling in the blanks as instructed in the code. Once you have implemented the loops, run the cell to train the model for 10 epochs. \n",
    "\n",
    "If you have limited computational resources, you may train for fewer epochs until the validation loss reaches below 0.1 (This can be reached after about 3 epochs). However, keep in mind that the performance of your model will be very poor on the translation task if it is not trained for enough epochs.\n",
    "\n",
    "Once you have completed the training, run the test cell to check if the training and validation loss have decreased to below 0.1. Remember to submit the trained model **model.pth** to Moodle along with your other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "17e63f9b-07b4-4d01-a62d-25b9deafaf5a",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ab754ff88ae6158e85c5829d0132425",
     "grade": false,
     "grade_id": "cell-3e78e5aa606c25be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The shape of the 2D attn_mask is torch.Size([7, 7]), but should be (6, 6).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m src_padding_mask \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcreate_pad_mask(src_batch)\n\u001b[0;32m     35\u001b[0m tgt_padding_mask \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcreate_pad_mask(tgt_batch)\n\u001b[1;32m---> 37\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     40\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vsize_tgt)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[146], line 67\u001b[0m, in \u001b[0;36mMyTransformer.forward\u001b[1;34m(self, src, tgt, src_padding_mask, tgt_padding_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, tgt, src_padding_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tgt_padding_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tgt_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# 1. pass source through encode block (name it as memory)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# 2. pass target and memory through decode block\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# 3. Project to vocabulary size  \u001b[39;00m\n\u001b[0;32m     65\u001b[0m     memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(src, src_padding_mask)\n\u001b[1;32m---> 67\u001b[0m     output_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output_decoder)\n\u001b[0;32m     71\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[146], line 51\u001b[0m, in \u001b[0;36mMyTransformer.decode\u001b[1;34m(self, tgt, memory, tgt_mask, tgt_padding_mask)\u001b[0m\n\u001b[0;32m     49\u001b[0m tgt_embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_tgt(tgt)\n\u001b[0;32m     50\u001b[0m tgt_embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(tgt_embedded)\n\u001b[1;32m---> 51\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_padding_mask\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoded\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:602\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    599\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 602\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:1087\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x))\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1086\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m-> 1087\u001b[0m         x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1088\u001b[0m     )\n\u001b[0;32m   1089\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\n\u001b[0;32m   1090\u001b[0m         x\n\u001b[0;32m   1091\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(\n\u001b[0;32m   1092\u001b[0m             x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m     )\n\u001b[0;32m   1095\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:1107\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1102\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1343\u001b[0m         query,\n\u001b[0;32m   1344\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\functional.py:6131\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   6129\u001b[0m     correct_2d_size \u001b[38;5;241m=\u001b[39m (tgt_len, src_len)\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m correct_2d_size:\n\u001b[1;32m-> 6131\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   6132\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the 2D attn_mask is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_2d_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6133\u001b[0m         )\n\u001b[0;32m   6134\u001b[0m     attn_mask \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   6135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The shape of the 2D attn_mask is torch.Size([7, 7]), but should be (6, 6)."
     ]
    }
   ],
   "source": [
    "# Training \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "num_epochs = 10\n",
    "\n",
    "if not skip_training:\n",
    "    epoch_train_losses = []\n",
    "    epoch_validation_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model = model.to(device)\n",
    "        model.train()  # Set model to training mode\n",
    "        total_loss = 0\n",
    "        num_samples = 0\n",
    "        for src_batch, tgt_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # set input source as src_batch\n",
    "            # set input target as start of target sentence untill -1 (i.e. discard the last token) (past) [name it as tgt_input]\n",
    "            # set expexted target as target sentence from 1 to the end (i.e. discard the first token) (future) [name it as tgt_expected]\n",
    "            # Use input source and input target (tgt_input) as input to the model\n",
    "            # The expexted target will be used in loss to compare it with the model output.\n",
    "            # Remember to use padding and target causal masks on the model call:\n",
    "            # get padding mask of source,\n",
    "            # get padding mask of input target, convert it to float (.float()),\n",
    "            # get tgt_mask of input target,\n",
    "            # pass inout source, input target, source padding mask, and tgt_mask to the model to get the predictions (output).\n",
    "            \n",
    "            src_batch = src_batch.to(device)\n",
    "            tgt_batch = tgt_batch.to(device)\n",
    "            \n",
    "            tgt_input = tgt_batch[:, :-1]\n",
    "            tgt_expected = tgt_batch[:, 1:]\n",
    "\n",
    "            tgt_mask = model.get_tgt_mask(tgt_batch)\n",
    "            src_padding_mask = model.create_pad_mask(src_batch)\n",
    "            tgt_padding_mask = model.create_pad_mask(tgt_batch)\n",
    "\n",
    "            output = model(src_batch, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask )\n",
    "            \n",
    "            output = output.to(device)\n",
    "            output = output.contiguous().view(-1, vsize_tgt)\n",
    "            tgt_expected = tgt_expected.contiguous().view(-1)    \n",
    "            \n",
    "            loss = criterion(output, tgt_expected)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_samples += src_batch.shape[0]\n",
    "    \n",
    "        epoch_train_loss = total_loss / len(train_loader)\n",
    "        epoch_train_loss = round(epoch_train_loss, 4)\n",
    "        epoch_train_losses.append(epoch_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_train_loss}\")\n",
    "        \n",
    "        ################################################################\n",
    "        \n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        num_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for src_batch, tgt_batch in val_loader:\n",
    "                # set input source as src_batch\n",
    "                # set input target as start of target sentence untill -1 (i.e. discard the last token) (past) [name it as tgt_input]\n",
    "                # set expexted target as target sentence from 1 to the end (i.e. discard the first token) (future) [name it as tgt_expected]\n",
    "                # Use input source and input target (tgt_input) as input to the model\n",
    "                # Use expexted target in loss to compare it with the model output.\n",
    "                # Remember to use padding and target causal masks on the model call:\n",
    "                # get padding mask of source,\n",
    "                # get padding mask of input target, convert it to float (.float()),\n",
    "                # get tgt_mask of input target,\n",
    "                # pass inout source, input target, source padding mask, and tgt_mask to the model to get the predictions (output).\n",
    "                    \n",
    "                src_batch = src_batch.to(device)\n",
    "                tgt_batch = tgt_batch.to(device)\n",
    "                \n",
    "                tgt_input = tgt_batch[:, :-1]\n",
    "                tgt_expected = tgt_batch[:, 1:]\n",
    "\n",
    "                tgt_mask = model.get_tgt_mask(tgt_batch)\n",
    "                src_padding_mask = model.create_pad_mask(src_batch)\n",
    "                tgt_padding_mask = model.create_pad_mask(tgt_batch)\n",
    "\n",
    "                output = model(src_batch, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask )\n",
    "                \n",
    "                output = output.to(device)\n",
    "                output = output.contiguous().view(-1, vsize_tgt)\n",
    "                tgt_expected = tgt_expected.contiguous().view(-1)  \n",
    "                loss = criterion(output, tgt_expected)\n",
    "                validation_loss += loss.item()\n",
    "                num_samples += src_batch.shape[0]\n",
    "                \n",
    "            epoch_validation_loss = validation_loss / len(val_loader)\n",
    "            epoch_validation_loss = round(epoch_validation_loss, 4)\n",
    "            epoch_validation_losses.append(epoch_validation_loss)\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {epoch_validation_loss}\")\n",
    "        torch.save(model.state_dict(), 'model.pth')   \n",
    "            \n",
    "    print(\"Training completed.\")\n",
    "    torch.save(model.state_dict(), 'model.pth') \n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epochs, epoch_train_losses, label='Train Loss', color='blue', marker='o')\n",
    "    plt.plot(epochs, epoch_validation_losses, label='Validation Loss', color='red', marker='x')\n",
    "    plt.title('Train vs Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "463af138-b291-49b6-a74c-521328e684a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10bd60e70fa72570e2d7362277a91833",
     "grade": false,
     "grade_id": "cell-2558e4570d6e8afe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Visible tests for checking the performance of the trained model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Test if the train and validation losses are within the correct range\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_training:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mepoch_train_loss\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m      7\u001b[0m         all_tests_successful \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_train_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be smaller than 0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch_train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Visible tests here\n",
    "all_tests_successful = True\n",
    "# Visible tests for checking the performance of the trained model\n",
    "# Test if the train and validation losses are within the correct range\n",
    "if not skip_training:\n",
    "    if not (epoch_train_loss <= 0.1):\n",
    "        all_tests_successful = False\n",
    "        raise AssertionError(f\"Training loss {epoch_train_loss} must be smaller than 0.1\")\n",
    "        \n",
    "    if not (epoch_validation_loss <= 0.1):\n",
    "        all_tests_successful = False\n",
    "        raise AssertionError(f\"Validation loss {epoch_validation_loss} must be smaller than 0.1\")\n",
    "    \n",
    "    if all_tests_successful: \n",
    "        success_str = \"Good job! The final train loss and validation loss are in the expected range!\"\n",
    "        print(f\"\\033[92m{success_str}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72146f6b-9f87-4d59-9833-d62c12257eba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f50a38fd0bad2c9220ee97afcb6e0b4",
     "grade": true,
     "grade_id": "cell-1ac2935596c4dc68",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d97d50-f344-4bd0-9933-31e0967db8ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cd6f4b79c9eb03096892f79e8f40433",
     "grade": false,
     "grade_id": "cell-c54877793b096ca1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 4: Autoregressive Translation (5 points)\n",
    "\n",
    "Finally, we are going to use the trained model to perform an actual translation task, translating French sentences into English. Exciting!\n",
    "\n",
    "The inference works in an autoregressive manner. This means that, during the translation process, the model generates each token in the target sequence one at a time, using the previously generated token as input for predicting the next one. At each step, the model uses the encoded source sentence along with the target sequence generated so far to predict the next word. This approach allows the model to produce the translation step by step, instead of generating the entire sequence at once.\n",
    "\n",
    "The steps for translation are as follows:\n",
    "\n",
    "**Source Sentence Encoding:** First, we obtain the source sequence embedding and pass it through the encoder to obtain its encoded representation.\n",
    "\n",
    "**Initializing Target Sentence with <SOS> Token:** We initialize the target sentence with the special <SOS> (Start Of Sentence) token, which indicates the beginning of the translation.\n",
    "\n",
    "**Autoregressive Loop to Translate Target Tokens One at a Time:** We enter a loop where the model predicts the next token in the sequence based on the previously generated token and the encoded source sentence. This loop continues until the model predicts the <EOS> (End Of Sentence) token or the maximum sequence length is reached.\n",
    "\n",
    "In the cell below, fill in the blanks as instructed to create the translation loop for the provided example sentences. Once you have completed the template, run it and observe the printed translation results. \n",
    "\n",
    "Remeber to submit **'translation.npy'** to Moodle along with your other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b511cb3-8a3d-4d83-b403-ffb9f4b65f5e",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d107bba2e8b29eabdd5bde898afb0b",
     "grade": false,
     "grade_id": "cell-4dae7ac8dd1330c2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type int64_t without overflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 1. create src_padding_mask\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 2. get \"memory\" by passing source with create src_padding_mask through encode block (model.encode)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m src_padding_mask \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcreate_pad_mask(src_batch)\n\u001b[1;32m---> 26\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# initialize the predicted tgt_tokens (translation) with start token\u001b[39;00m\n\u001b[0;32m     29\u001b[0m tgt_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(start_token)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#(1,1)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:408\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    386\u001b[0m     src: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m     is_causal: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    390\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Pass the input through the encoder layers in turn.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m        see the docs in :class:`~torch.nn.Transformer`.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m     src_key_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_canonical_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc_key_padding_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_none_or_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39m_canonical_mask(\n\u001b[0;32m    417\u001b[0m         mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    418\u001b[0m         mask_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m         check_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    423\u001b[0m     )\n\u001b[0;32m    425\u001b[0m     output \u001b[38;5;241m=\u001b[39m src\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\dl_course\\lib\\site-packages\\torch\\nn\\functional.py:5854\u001b[0m, in \u001b[0;36m_canonical_mask\u001b[1;34m(mask, mask_name, other_type, other_name, target_type, check_other)\u001b[0m\n\u001b[0;32m   5849\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   5850\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupport for mismatched \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5851\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis deprecated. Use same type for both instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5852\u001b[0m             )\n\u001b[0;32m   5853\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mask_is_float:\n\u001b[1;32m-> 5854\u001b[0m         mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5855\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5856\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5857\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[1;31mRuntimeError\u001b[0m: value cannot be converted to type int64_t without overflow"
     ]
    }
   ],
   "source": [
    "seq_len=10\n",
    "start_token=1\n",
    "end_token=2\n",
    "model.eval()  \n",
    "\n",
    "# Convert src_sentence to tokenized integers in the vocabulary dictionary \n",
    "example_source_sentences = [\"new jersey est parfois calme pendant l' automne.\", \"california est généralement calme en mars.\"]\n",
    "example_tokenized = tokenize(example_source_sentences)\n",
    "src_sentences = []\n",
    "for ex in example_tokenized:\n",
    "    ex_inds = []\n",
    "    for t in ex:\n",
    "        t_ind = fr_word2idx [t]\n",
    "        ex_inds.append(t_ind)\n",
    "    src_sentences.append(ex_inds)    \n",
    "\n",
    "translated_sequences = []\n",
    "for counter, src_sentence in enumerate(src_sentences):    \n",
    "    # Convert source tokens to Tensor \n",
    "    src_tensor = torch.tensor(src_sentence, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, src_seq_length)\n",
    "    \n",
    "    # 1. create src_padding_mask\n",
    "    # 2. get \"memory\" by passing source with create src_padding_mask through encode block (model.encode)\n",
    "    \n",
    "    src_padding_mask = model.create_pad_mask(src_batch)\n",
    "    memory = model.encoder(src_tensor, src_key_padding_mask=src_padding_mask)\n",
    "    \n",
    "    # initialize the predicted tgt_tokens (translation) with start token\n",
    "    tgt_tokens = torch.ones(1, 1).fill_(start_token).type(torch.long).to(device) #(1,1)\n",
    "\n",
    "    for i in range(seq_len-1):\n",
    "        # 1. Mask out the unpredicted tokens in the target (i.e., get tgt_mask)\n",
    "        # 2. get output by passing target (the generated part up to current `i`) and memory to decode block (model.decode)\n",
    "        # 3. remember to pass also tgt_mask\n",
    "        # 4. get a probability vector by passing output through linear layer (projection to vocabulary size)\n",
    "        # 5. use \"torch.max\" to get the index of the predicted word\n",
    "        # 6. Convert it to a tensor on device (name it as \"next_tgt_item\")\n",
    "        # 7. add \"next_tgt_item\" to tgt_tokens (use torch.cat)\n",
    "        # 8. Stop (break) if \"end_token\" is generated\n",
    "        tgt_mask = model.get_tgt_mask(tgt_batch)\n",
    "        tgt_padding_mask = model.create_pad_mask(tgt_batch)\n",
    "        output = model(src_batch, tgt_batch, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask )\n",
    "        _, next_token = torch.max(output, dim=1)\n",
    "        next_tgt_item = next_token.unsqueeze(1).to(device)\n",
    "        tgt_tokens = torch.cat([tgt_tokens, next_tgt_item], dim=1)\n",
    "\n",
    "        if next_token.item() == end_token:\n",
    "            break\n",
    "\n",
    "    \n",
    "    translated_tokens = tgt_tokens.squeeze().tolist()\n",
    "    translated_sentence = ' '.join ([en_idx2word[i] for i in translated_tokens[1:]])\n",
    "    translated_sequences.append(translated_tokens)\n",
    "    print(\"original_sentence:\", example_source_sentences[counter])\n",
    "    print(\"translated_sentence:\", translated_sentence)\n",
    "    print(10*'-')\n",
    "\n",
    "np.save('translation.npy', np.array(translated_sequences, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7f314-8db1-408a-bf5f-e91daf531029",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "922697a48c9fcbd294bf44dd665bf0d0",
     "grade": true,
     "grade_id": "cell-afe70a33546d08c5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
